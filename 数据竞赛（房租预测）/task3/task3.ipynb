{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 任务3 特征工程&特征选择(3天)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征工程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "train = pd.read_csv('../train_data.csv')\n",
    "test = pd.read_csv('../test_a.csv')\n",
    "target_train = train.pop('tradeMoney')\n",
    "# target_test = test.pop('tradeMoney')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def newfeature(data):\n",
    "def newfeature(train, test):\n",
    "\n",
    "    train['data_type'] = 0\n",
    "    test['data_type'] = 1\n",
    "    data = pd.concat([train, test], axis=0, join='outer')\n",
    "\n",
    "    # 将houseType转为'Room'，'Hall'，'Bath'\n",
    "    def Room(x):\n",
    "        Room = int(x.split('室')[0])\n",
    "        return Room\n",
    "    def Hall(x):\n",
    "        Hall = int(x.split(\"室\")[1].split(\"厅\")[0])\n",
    "        return Hall\n",
    "    def Bath(x):\n",
    "        Bath = int(x.split(\"室\")[1].split(\"厅\")[1].split(\"卫\")[0])\n",
    "        return Bath\n",
    "\n",
    "    data['Room'] = data['houseType'].apply(lambda x: Room(x))\n",
    "    data['Hall'] = data['houseType'].apply(lambda x: Hall(x))\n",
    "    data['Bath'] = data['houseType'].apply(lambda x: Bath(x))\n",
    "    data['Room_Bath'] = (data['Bath']+1) / (data['Room']+1)\n",
    "    # 填充租房类型\n",
    "    data.loc[(data['rentType'] == '未知方式') & (data['Room'] <= 1), 'rentType'] = '整租'\n",
    "    # print(data.loc[(data['rentType']=='未知方式')&(data['Room_Bath']>1),'rentType'])\n",
    "    data.loc[(data['rentType'] == '未知方式') & (data['Room_Bath'] > 1), 'rentType'] = '合租'\n",
    "    data.loc[(data['rentType'] == '未知方式') & (data['Room'] > 1) & (data['area'] < 50), 'rentType'] = '合租'\n",
    "    data.loc[(data['rentType'] == '未知方式') & (data['area'] / data['Room'] < 20), 'rentType'] = '合租'\n",
    "    # data.loc[(data['rentType']=='未知方式')&(data['area']>60),'rentType']='合租'\n",
    "    data.loc[(data['rentType'] == '未知方式') & (data['area'] <= 50) & (data['Room'] == 2), 'rentType'] = '合租'\n",
    "    data.loc[(data['rentType'] == '未知方式') & (data['area'] > 60) & (data['Room'] == 2), 'rentType'] = '整租'\n",
    "    data.loc[(data['rentType'] == '未知方式') & (data['area'] <= 60) & (data['Room'] == 3), 'rentType'] = '合租'\n",
    "    data.loc[(data['rentType'] == '未知方式') & (data['area'] > 60) & (data['Room'] == 3), 'rentType'] = '整租'\n",
    "    data.loc[(data['rentType'] == '未知方式') & (data['area'] >= 100) & (data['Room'] > 3), 'rentType'] = '整租'\n",
    "\n",
    "    # data.drop('Room_Bath', axis=1, inplace=True)\n",
    "    # 提升0.0001\n",
    "    def month(x):\n",
    "        month = int(x.split('/')[1])\n",
    "        return month\n",
    "    # def day(x):\n",
    "    #     day = int(x.split('/')[2])\n",
    "    #     return day\n",
    "    # 结果变差\n",
    "\n",
    "    # 分割交易时间\n",
    "    # data['year']=data['tradeTime'].apply(lambda x:year(x))\n",
    "    data['month'] = data['tradeTime'].apply(lambda x: month(x))\n",
    "    # data['day'] = data['tradeTime'].apply(lambda x: day(x))# 结果变差\n",
    "    #     data['pv/uv'] = data['pv'] / data['uv']\n",
    "    #     data['房间总数'] = data['室'] + data['厅'] + data['卫']\n",
    "\n",
    "    # 合并部分配套设施特征\n",
    "    data['trainsportNum'] = 5 * data['subwayStationNum'] / data['subwayStationNum'].mean() + data['busStationNum'] / \\\n",
    "                                                                                             data[\n",
    "                                                                                                 'busStationNum'].mean()\n",
    "    data['all_SchoolNum'] = 2 * data['interSchoolNum'] / data['interSchoolNum'].mean() + data['schoolNum'] / data[\n",
    "        'schoolNum'].mean() \\\n",
    "                            + data['privateSchoolNum'] / data['privateSchoolNum'].mean()\n",
    "    data['all_hospitalNum'] = 2 * data['hospitalNum'] / data['hospitalNum'].mean() + \\\n",
    "                              data['drugStoreNum'] / data['drugStoreNum'].mean()\n",
    "    data['all_mall'] = data['mallNum'] / data['mallNum'].mean() + \\\n",
    "                       data['superMarketNum'] / data['superMarketNum'].mean()\n",
    "    data['otherNum'] = data['gymNum'] / data['gymNum'].mean() + data['bankNum'] / data['bankNum'].mean() + \\\n",
    "                       data['shopNum'] / data['shopNum'].mean() + 2 * data['parkNum'] / data['parkNum'].mean()\n",
    "\n",
    "    data.drop(['subwayStationNum', 'busStationNum',\n",
    "               'interSchoolNum', 'schoolNum', 'privateSchoolNum',\n",
    "               'hospitalNum', 'drugStoreNum', 'mallNum', 'superMarketNum', 'gymNum', 'bankNum', 'shopNum', 'parkNum'],\n",
    "              axis=1, inplace=True)\n",
    "    # 提升0.0005\n",
    "    \n",
    "#     data['houseType_1sumcsu']=data['Bath'].map(lambda x:str(x))+data['month'].map(lambda x:str(x))\n",
    "#     data['houseType_2sumcsu']=data['Bath'].map(lambda x:str(x))+data['communityName']\n",
    "#     data['houseType_3sumcsu']=data['Bath'].map(lambda x:str(x))+data['plate']\n",
    "    \n",
    "    data.drop('houseType', axis=1, inplace=True)\n",
    "    data.drop('tradeTime', axis=1, inplace=True)\n",
    "    \n",
    "    data[\"area\"] = data[\"area\"].astype(int)\n",
    "\n",
    "\n",
    "    # categorical_feats = ['rentType', 'houseFloor', 'houseToward', 'houseDecoration', 'communityName','region', 'plate']\n",
    "    categorical_feats = ['rentType', 'houseFloor', 'houseToward', 'houseDecoration',  'region', 'plate','cluster']\n",
    "\n",
    "    # return data, categorical_feats\n",
    "\n",
    "    new_train = data[data['data_type'] == 0]\n",
    "    new_test = data[data['data_type'] == 1]\n",
    "\n",
    "    return new_train, new_test\n",
    "\n",
    "train, test = newfeature(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算统计特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['ID', 'area', 'rentType', 'houseFloor', 'totalFloor', 'houseToward',\n       'houseDecoration', 'communityName', 'city', 'region', 'plate',\n       'buildYear', 'saleSecHouseNum', 'totalTradeMoney', 'totalTradeArea',\n       'tradeMeanPrice', 'tradeSecNum', 'totalNewTradeMoney',\n       'totalNewTradeArea', 'tradeNewMeanPrice', 'tradeNewNum', 'remainNewNum',\n       'supplyNewNum', 'supplyLandNum', 'supplyLandArea', 'tradeLandNum',\n       'tradeLandArea', 'landTotalPrice', 'landMeanPrice', 'totalWorkers',\n       'newWorkers', 'residentPopulation', 'pv', 'uv', 'lookNum', 'data_type',\n       'Room', 'Hall', 'Bath', 'Room_Bath', 'month', 'trainsportNum',\n       'all_SchoolNum', 'all_hospitalNum', 'all_mall', 'otherNum',\n       'count_communityName', 'count_buildYear', 'count_totalFloor',\n       'count_communityName_totalFloor', 'count_communityName_newWorkers',\n       'count_communityName_totalTradeMoney'],\n      dtype='object')"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#计算统计特征\n",
    "def featureCount(train,test):\n",
    "    train['data_type'] = 0\n",
    "    test['data_type'] = 1\n",
    "    data = pd.concat([train, test], axis=0, join='outer')\n",
    "    def feature_count(data, features=[]):\n",
    "        new_feature = 'count'\n",
    "        for i in features:\n",
    "            new_feature += '_' + i\n",
    "        temp = data.groupby(features).size().reset_index().rename(columns={0: new_feature})\n",
    "        data = data.merge(temp, 'left', on=features)\n",
    "        return data\n",
    "\n",
    "    data = feature_count(data, ['communityName'])\n",
    "    data = feature_count(data, ['buildYear'])\n",
    "    data = feature_count(data, ['totalFloor'])\n",
    "    data = feature_count(data, ['communityName', 'totalFloor'])\n",
    "    data = feature_count(data, ['communityName', 'newWorkers'])\n",
    "    data = feature_count(data, ['communityName', 'totalTradeMoney'])\n",
    "    new_train = data[data['data_type'] == 0]\n",
    "    new_test = data[data['data_type'] == 1]\n",
    "    # new_train.drop('data_type', axis=1, inplace=True)\n",
    "    # new_test.drop(['data_type'], axis=1, inplace=True)\n",
    "    return new_train, new_test\n",
    "    \n",
    "train, test = featureCount(train, test)\n",
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 填充缺失值\n",
    "# def preprocessingData(data):\n",
    "def preprocessingData(train, test):\n",
    "\n",
    "    train['data_type'] = 0\n",
    "    test['data_type'] = 1\n",
    "    data = pd.concat([train, test], axis=0, join='outer')\n",
    "\n",
    "  # 将buildYear列转换为整型数据\n",
    "    buildYearmean = pd.DataFrame(data[data['buildYear'] != '暂无信息']['buildYear'].mode())\n",
    "    data.loc[data[data['buildYear'] == '暂无信息'].index, 'buildYear'] = buildYearmean.iloc[0, 0]\n",
    "    data['buildYear'] = data['buildYear'].astype('int')\n",
    "\n",
    "    # 处理pv和uv的空值\n",
    "    data['pv'].fillna(data['pv'].mean(), inplace=True)\n",
    "    data['uv'].fillna(data['uv'].mean(), inplace=True)\n",
    "    data['pv'] = data['pv'].astype('int')\n",
    "    data['uv'] = data['uv'].astype('int')\n",
    "\n",
    "    # 去掉部分特征\n",
    "    data.drop('city', axis=1, inplace=True)\n",
    "    data.drop('ID', axis=1, inplace=True)\n",
    "\n",
    "    # return data\n",
    "\n",
    "    new_train = data[data['data_type'] == 0]\n",
    "    new_test = data[data['data_type'] == 1]\n",
    "\n",
    "    return new_train, new_test\n",
    "\n",
    "train, test = preprocessingData(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## groupby方法生成统计特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#groupby生成统计特征：mean,std等\n",
    "\n",
    "def gourpby(train,test):\n",
    "    train['data_type'] = 0\n",
    "    test['data_type'] = 1\n",
    "    data = pd.concat([train, test], axis=0, join='outer')\n",
    "    columns = ['rentType', 'houseFloor', 'houseToward', 'houseDecoration', 'communityName', 'region', 'plate']\n",
    "    for feature in columns:\n",
    "        data[feature] = LabelEncoder().fit_transform(data[feature])\n",
    "\n",
    "\n",
    "    temp = data.groupby('communityName')['area'].agg({'com_area_mean': 'mean', 'com_area_std': 'std'})\n",
    "    temp.fillna(0, inplace=True)\n",
    "    data = data.merge(temp, on='communityName', how='left')\n",
    "    \n",
    "    data['price_per_area'] = data.tradeMeanPrice / data.area * 100\n",
    "    temp = data.groupby('communityName')['price_per_area'].agg(\n",
    "        {'comm_price_mean': 'mean', 'comm_price_std': 'std'})\n",
    "    temp.fillna(0, inplace=True)\n",
    "    data = data.merge(temp, on='communityName', how='left')\n",
    "\n",
    "   \n",
    "    temp = data.groupby('plate')['price_per_area'].agg(\n",
    "        {'plate_price_mean': 'mean', 'plate_price_std': 'std'})\n",
    "    temp.fillna(0, inplace=True)\n",
    "    data = data.merge(temp, on='plate', how='left')\n",
    "    data.drop('price_per_area', axis=1, inplace=True)\n",
    "\n",
    "    temp = data.groupby('plate')['area'].agg({'plate_area_mean': 'mean', 'plate_area_std': 'std'})\n",
    "    temp.fillna(0, inplace=True)\n",
    "    data = data.merge(temp, on='plate', how='left')\n",
    "    \n",
    "    temp = data.groupby(['plate'])['buildYear'].agg({'plate_year_mean': 'mean', 'plate_year_std': 'std'})\n",
    "    data = data.merge(temp, on='plate', how='left')\n",
    "    data.plate_year_mean = data.plate_year_mean.astype('int')\n",
    "    data['comm_plate_year_diff'] = data.buildYear - data.plate_year_mean\n",
    "    data.drop('plate_year_mean', axis=1, inplace=True)\n",
    "\n",
    "    temp = data.groupby('plate')['trainsportNum'].agg('sum').reset_index(name='plate_trainsportNum')\n",
    "    data = data.merge(temp, on='plate', how='left')\n",
    "    temp = data.groupby(['communityName', 'plate'])['trainsportNum'].agg('sum').reset_index(name='com_trainsportNum')\n",
    "    data = data.merge(temp, on=['communityName', 'plate'], how='left')\n",
    "    data['trainsportNum_ratio'] = list(map(lambda x, y: round(x / y, 3) if y != 0 else -1,\n",
    "                                           data['com_trainsportNum'], data['plate_trainsportNum']))\n",
    "    data = data.drop(['com_trainsportNum', 'plate_trainsportNum'], axis=1)\n",
    "\n",
    "    temp = data.groupby('plate')['all_SchoolNum'].agg('sum').reset_index(name='plate_all_SchoolNum')\n",
    "    data = data.merge(temp, on='plate', how='left')\n",
    "    temp = data.groupby(['communityName', 'plate'])['all_SchoolNum'].agg('sum').reset_index(name='com_all_SchoolNum')\n",
    "    data = data.merge(temp, on=['communityName', 'plate'], how='left')\n",
    "    data = data.drop(['com_all_SchoolNum', 'plate_all_SchoolNum'], axis=1)\n",
    "\n",
    "    temp = data.groupby(['communityName', 'plate'])['all_mall'].agg('sum').reset_index(name='com_all_mall')\n",
    "    data = data.merge(temp, on=['communityName', 'plate'], how='left')\n",
    "\n",
    "\n",
    "    temp = data.groupby('plate')['otherNum'].agg('sum').reset_index(name='plate_otherNum')\n",
    "    data = data.merge(temp, on='plate', how='left')\n",
    "    temp = data.groupby(['communityName', 'plate'])['otherNum'].agg('sum').reset_index(name='com_otherNum')\n",
    "    data = data.merge(temp, on=['communityName', 'plate'], how='left')\n",
    "    data['other_ratio'] = list(map(lambda x, y: round(x / y, 3) if y != 0 else -1,\n",
    "                                   data['com_otherNum'], data['plate_otherNum']))\n",
    "    data = data.drop(['com_otherNum', 'plate_otherNum'], axis=1)\n",
    "\n",
    "    temp = data.groupby(['month', 'communityName']).size().reset_index(name='communityName_saleNum')\n",
    "    data = data.merge(temp, on=['month', 'communityName'], how='left')\n",
    "    temp = data.groupby(['month', 'plate']).size().reset_index(name='plate_saleNum')\n",
    "    data = data.merge(temp, on=['month', 'plate'], how='left')\n",
    "\n",
    "    data['sale_ratio'] = round((data.communityName_saleNum + 1) / (data.plate_saleNum + 1), 3)\n",
    "    data['sale_newworker_differ'] = 3 * data.plate_saleNum - data.newWorkers\n",
    "    data.drop(['communityName_saleNum', 'plate_saleNum'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "    new_train = data[data['data_type'] == 0]\n",
    "    new_test = data[data['data_type'] == 1]\n",
    "    new_train.drop('data_type', axis=1, inplace=True)\n",
    "    new_test.drop(['data_type'], axis=1, inplace=True)\n",
    "    return new_train, new_test\n",
    "\n",
    "train, test = gourpby(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-24T13:38:33.198959Z",
     "start_time": "2019-12-24T13:38:33.193970Z"
    }
   },
   "source": [
    "## 聚类方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0    31927\n1    11198\n2      784\nName: cluster, dtype: int64\n"
    }
   ],
   "source": [
    "#聚类\n",
    "def cluster(train,test):\n",
    "    from sklearn.mixture import GaussianMixture\n",
    "\n",
    "    train['data_type'] = 0\n",
    "    test['data_type'] = 1\n",
    "    data = pd.concat([train, test], axis=0, join='outer')\n",
    "    col = ['totalFloor',\n",
    "           'houseDecoration', 'communityName', 'region', 'plate', 'buildYear',\n",
    "\n",
    "           'tradeMeanPrice', 'tradeSecNum', 'totalNewTradeMoney',\n",
    "           'totalNewTradeArea', 'tradeNewMeanPrice', 'tradeNewNum', 'remainNewNum',\n",
    "\n",
    "           'landTotalPrice', 'landMeanPrice', 'totalWorkers',\n",
    "           'newWorkers', 'residentPopulation', 'lookNum',\n",
    "           'trainsportNum',\n",
    "           'all_SchoolNum', 'all_hospitalNum', 'all_mall', 'otherNum']\n",
    "\n",
    "    # EM\n",
    "    gmm = GaussianMixture(n_components=3, covariance_type='full', random_state=0)\n",
    "    data['cluster']= pd.DataFrame(gmm.fit_predict(data[col]))\n",
    "    print(data['cluster'].value_counts())\n",
    "\n",
    "\n",
    "    col1 = ['totalFloor','houseDecoration', 'communityName', 'region', 'plate', 'buildYear']\n",
    "    col2 = ['tradeMeanPrice', 'tradeSecNum', 'totalNewTradeMoney',\n",
    "            'totalNewTradeArea', 'tradeNewMeanPrice', 'tradeNewNum', 'remainNewNum',\n",
    "            'landTotalPrice', 'landMeanPrice', 'totalWorkers',\n",
    "            'newWorkers', 'residentPopulation', 'lookNum',\n",
    "            'trainsportNum',\n",
    "            'all_SchoolNum', 'all_hospitalNum', 'all_mall', 'otherNum']\n",
    "    for feature1 in col1:\n",
    "        for feature2 in col2:\n",
    "        \n",
    "            temp = data.groupby(['cluster',feature1])[feature2].agg('mean').reset_index(name=feature2+'_'+feature1+'_cluster_mean')\n",
    "            temp.fillna(0, inplace=True)\n",
    "       \n",
    "            data = data.merge(temp, on=['cluster', feature1], how='left')\n",
    "    # print(data)\n",
    "    \n",
    "   \n",
    "    new_train = data[data['data_type'] == 0]\n",
    "    new_test = data[data['data_type'] == 1]\n",
    "    new_train.drop('data_type', axis=1, inplace=True)\n",
    "    new_test.drop(['data_type'], axis=1, inplace=True)\n",
    "    \n",
    "    return new_train, new_test\n",
    "\n",
    "train, test = cluster(train, test)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## log平滑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 过大量级值取log平滑（针对线性模型有效）\n",
    "big_num_cols = ['totalTradeMoney','totalTradeArea','tradeMeanPrice','totalNewTradeMoney', 'totalNewTradeArea',\n",
    "                'tradeNewMeanPrice','remainNewNum', 'supplyNewNum', 'supplyLandArea',\n",
    "                'tradeLandArea','landTotalPrice','landMeanPrice','totalWorkers','newWorkers',\n",
    "                'residentPopulation','pv','uv']\n",
    "for col in big_num_cols:\n",
    "        train[col] = train[col].map(lambda x: np.log1p(x))\n",
    "        test[col] = test[col].map(lambda x: np.log1p(x))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.fillna(0, inplace=True)\n",
    "test.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "训练集结果： -46.30798817319642\n"
    }
   ],
   "source": [
    "#对比特征工程前后线性模型结果情况\n",
    "test=test.fillna(0)\n",
    "# Lasso回归\n",
    "from sklearn.linear_model import Lasso\n",
    "lasso=Lasso(alpha=0.1)\n",
    "lasso.fit(train,target_train)\n",
    "#预测测试集和训练集结果\n",
    "y_pred_train=lasso.predict(train)\n",
    "y_pred_test=lasso.predict(test)\n",
    "\n",
    "#对比结果\n",
    "from sklearn.metrics import r2_score\n",
    "score_train=r2_score(y_pred_train,target_train)\n",
    "print(\"训练集结果：\",score_train)\n",
    "# score_test=r2_score(y_pred_test, target_test)\n",
    "# print(\"测试集结果：\",score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-24T12:31:08.989972Z",
     "start_time": "2019-12-24T12:31:08.986978Z"
    }
   },
   "source": [
    "# 特征选择"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "当数据预处理完成后，需要选择有意义的特征输入机器学习的算法和模型进行训练。通常来说，从两个方面考虑来选择特征：\n",
    "\n",
    "- 特征是否发散：如果一个特征不发散，例如方差接近于0，也就是说样本在这个特征上基本上没有差异，这个特征对于样本的区分并没有什么用。\n",
    "- 特征与目标的相关性：这点比较显见，与目标相关性高的特征，应当优选选择。\n",
    "\n",
    "根据特征选择的形式又可以将特征选择方法分为3种：\n",
    "- Filter：过滤法，按照发散性或者相关性对各个特征进行评分，设定阈值或者待选择阈值的个数，选择特征。\n",
    "- Wrapper：包装法，根据目标函数（通常是预测效果评分），每次选择若干特征，或者排除若干特征。\n",
    "- Embedded：嵌入法，先使用某些机器学习的算法和模型进行训练，得到各个特征的权值系数，根据系数从大到小选择特征。类似于Filter方法，但是是通过训练来确定特征的优劣。\n",
    "\n",
    "特征选择主要有两个目的：\n",
    "\n",
    "- 减少特征数量、降维，使模型泛化能力更强，减少过拟合；\n",
    "- 增强对特征和特征值之间的理解。\n",
    "\n",
    "拿到数据集，一个特征选择方法，往往很难同时完成这两个目的。通常情况下，选择一种自己最熟悉或者最方便的特征选择方法（往往目的是降维，而忽略了对特征和数据理解的目的）。[1]\n",
    "\n",
    "[1] https://www.cnblogs.com/stevenlk/p/6543628.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.9078571428571429"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    " \n",
    "y_true = [1,2,4]\n",
    "y_pred = [1.3,2.5,3.7]\n",
    "r2_score(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 相关系数法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(41440, 173)\n(41440, 150)\n[  0   1   2   3   5   6   7   8   9  11  12  13  14  15  16  17  19  20\n  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  37  38  39\n  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  57  58\n  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76\n  77  78  79  80  81  82  84  85  86  87  88  89  92  93  94  95  96  97\n  98  99 100 101 102 103 104 105 107 108 109 110 111 112 113 114 115 116\n 117 118 119 121 122 123 124 129 131 132 134 135 137 138 139 140 141 143\n 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n 164 165 166 167 168 170]\n150\nIndex(['area', 'rentType', 'houseFloor', 'totalFloor', 'houseDecoration',\n       'communityName', 'region', 'plate', 'buildYear', 'totalTradeMoney',\n       ...\n       'totalNewTradeArea_buildYear_cluster_mean',\n       'tradeNewMeanPrice_buildYear_cluster_mean',\n       'tradeNewNum_buildYear_cluster_mean',\n       'remainNewNum_buildYear_cluster_mean',\n       'totalWorkers_buildYear_cluster_mean',\n       'newWorkers_buildYear_cluster_mean',\n       'residentPopulation_buildYear_cluster_mean',\n       'lookNum_buildYear_cluster_mean',\n       'trainsportNum_buildYear_cluster_mean',\n       'all_hospitalNum_buildYear_cluster_mean'],\n      dtype='object', length=150)\n(2469, 150)\n训练集结果： -48.449809054473015\n"
    }
   ],
   "source": [
    "#相关系数法特征选择\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "print(train.shape)\n",
    "\n",
    "# sk=SelectKBest(k=150)\n",
    "sk=SelectKBest(score_func=f_regression, k=150)\n",
    "new_train=sk.fit_transform(train,target_train)\n",
    "print(new_train.shape)\n",
    "\n",
    "# 获取对应列索引\n",
    "select_columns=sk.get_support(indices = True)\n",
    "print(select_columns)\n",
    "print(len(select_columns))\n",
    "\n",
    "# 获取对应列名\n",
    "print(test.columns[select_columns])\n",
    "select_columns_name=test.columns[select_columns]\n",
    "new_test=test[select_columns_name]\n",
    "print(new_test.shape)\n",
    "# Lasso回归\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso=Lasso(alpha=0.1)\n",
    "lasso.fit(new_train,target_train)\n",
    "#预测测试集和训练集结果\n",
    "y_pred_train=lasso.predict(new_train)\n",
    "\n",
    "y_pred_test=lasso.predict(new_test)\n",
    "\n",
    "#对比结果\n",
    "from sklearn.metrics import r2_score\n",
    "score_train=r2_score(y_pred_train,target_train)\n",
    "print(\"训练集结果：\",score_train)\n",
    "# score_test=r2_score(y_pred_test, target_test)\n",
    "# print(\"测试集结果：\",score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "['area', 'rentType', 'houseFloor', 'totalFloor', 'houseToward', 'houseDecoration', 'communityName', 'region', 'plate', 'buildYear', 'saleSecHouseNum', 'totalTradeMoney', 'totalTradeArea', 'tradeMeanPrice', 'tradeSecNum', 'totalNewTradeMoney', 'totalNewTradeArea', 'tradeNewMeanPrice', 'tradeNewNum', 'remainNewNum', 'supplyNewNum', 'supplyLandNum', 'supplyLandArea', 'tradeLandNum', 'tradeLandArea', 'landTotalPrice', 'landMeanPrice', 'totalWorkers', 'newWorkers', 'residentPopulation', 'pv', 'uv', 'lookNum', 'Room', 'Hall', 'Bath', 'Room_Bath', 'month', 'trainsportNum', 'all_SchoolNum', 'all_hospitalNum', 'all_mall', 'otherNum', 'count_communityName', 'count_buildYear', 'count_totalFloor', 'count_communityName_totalFloor', 'count_communityName_newWorkers', 'count_communityName_totalTradeMoney', 'com_area_mean', 'com_area_std', 'comm_price_std', 'plate_price_mean', 'plate_price_std', 'plate_area_mean', 'plate_area_std', 'plate_year_std', 'comm_plate_year_diff', 'trainsportNum_ratio', 'com_all_mall', 'other_ratio', 'sale_ratio', 'sale_newworker_differ', 'cluster', 'tradeMeanPrice_totalFloor_cluster_mean', 'tradeSecNum_totalFloor_cluster_mean', 'totalNewTradeArea_totalFloor_cluster_mean', 'tradeNewMeanPrice_totalFloor_cluster_mean', 'tradeNewNum_totalFloor_cluster_mean', 'remainNewNum_totalFloor_cluster_mean', 'landMeanPrice_totalFloor_cluster_mean', 'totalWorkers_totalFloor_cluster_mean', 'newWorkers_totalFloor_cluster_mean', 'residentPopulation_totalFloor_cluster_mean', 'lookNum_totalFloor_cluster_mean', 'trainsportNum_totalFloor_cluster_mean', 'all_SchoolNum_totalFloor_cluster_mean', 'all_hospitalNum_totalFloor_cluster_mean', 'all_mall_totalFloor_cluster_mean', 'otherNum_totalFloor_cluster_mean', 'tradeMeanPrice_houseDecoration_cluster_mean', 'tradeSecNum_houseDecoration_cluster_mean', 'totalNewTradeArea_houseDecoration_cluster_mean', 'tradeNewMeanPrice_houseDecoration_cluster_mean', 'tradeNewNum_houseDecoration_cluster_mean', 'remainNewNum_houseDecoration_cluster_mean', 'landMeanPrice_houseDecoration_cluster_mean', 'totalWorkers_houseDecoration_cluster_mean', 'newWorkers_houseDecoration_cluster_mean', 'residentPopulation_houseDecoration_cluster_mean', 'lookNum_houseDecoration_cluster_mean', 'trainsportNum_houseDecoration_cluster_mean', 'all_SchoolNum_houseDecoration_cluster_mean', 'all_hospitalNum_houseDecoration_cluster_mean', 'all_mall_houseDecoration_cluster_mean', 'otherNum_houseDecoration_cluster_mean', 'tradeMeanPrice_communityName_cluster_mean', 'tradeSecNum_communityName_cluster_mean', 'totalNewTradeArea_communityName_cluster_mean', 'tradeNewMeanPrice_communityName_cluster_mean', 'tradeNewNum_communityName_cluster_mean', 'remainNewNum_communityName_cluster_mean', 'landMeanPrice_communityName_cluster_mean', 'totalWorkers_communityName_cluster_mean', 'newWorkers_communityName_cluster_mean', 'residentPopulation_communityName_cluster_mean', 'lookNum_communityName_cluster_mean', 'trainsportNum_communityName_cluster_mean', 'all_SchoolNum_communityName_cluster_mean', 'all_hospitalNum_communityName_cluster_mean', 'all_mall_communityName_cluster_mean', 'otherNum_communityName_cluster_mean', 'tradeMeanPrice_region_cluster_mean', 'tradeSecNum_region_cluster_mean', 'totalNewTradeArea_region_cluster_mean', 'tradeNewMeanPrice_region_cluster_mean', 'tradeNewNum_region_cluster_mean', 'remainNewNum_region_cluster_mean', 'landMeanPrice_region_cluster_mean', 'totalWorkers_region_cluster_mean', 'newWorkers_region_cluster_mean', 'residentPopulation_region_cluster_mean', 'lookNum_region_cluster_mean', 'trainsportNum_region_cluster_mean', 'all_SchoolNum_region_cluster_mean', 'all_hospitalNum_region_cluster_mean', 'all_mall_region_cluster_mean', 'otherNum_region_cluster_mean', 'tradeMeanPrice_plate_cluster_mean', 'tradeSecNum_plate_cluster_mean', 'totalNewTradeArea_plate_cluster_mean', 'tradeNewMeanPrice_plate_cluster_mean', 'tradeNewNum_plate_cluster_mean', 'remainNewNum_plate_cluster_mean', 'landMeanPrice_plate_cluster_mean', 'totalWorkers_plate_cluster_mean', 'newWorkers_plate_cluster_mean', 'residentPopulation_plate_cluster_mean', 'lookNum_plate_cluster_mean', 'trainsportNum_plate_cluster_mean', 'all_SchoolNum_plate_cluster_mean', 'all_hospitalNum_plate_cluster_mean', 'all_mall_plate_cluster_mean', 'otherNum_plate_cluster_mean', 'tradeMeanPrice_buildYear_cluster_mean', 'tradeSecNum_buildYear_cluster_mean', 'totalNewTradeArea_buildYear_cluster_mean', 'tradeNewMeanPrice_buildYear_cluster_mean', 'tradeNewNum_buildYear_cluster_mean', 'remainNewNum_buildYear_cluster_mean', 'landMeanPrice_buildYear_cluster_mean', 'totalWorkers_buildYear_cluster_mean', 'newWorkers_buildYear_cluster_mean', 'residentPopulation_buildYear_cluster_mean', 'lookNum_buildYear_cluster_mean', 'trainsportNum_buildYear_cluster_mean', 'all_SchoolNum_buildYear_cluster_mean', 'all_hospitalNum_buildYear_cluster_mean', 'all_mall_buildYear_cluster_mean', 'otherNum_buildYear_cluster_mean']\n训练集结果： -47.2477849632117\n"
    }
   ],
   "source": [
    "# Wrapper\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "rfe = RFE(lr, n_features_to_select=160)\n",
    "rfe.fit(train,target_train)\n",
    "\n",
    "RFE(estimator=LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
    "                               normalize=False),\n",
    "    n_features_to_select=40, step=1, verbose=0)\n",
    "\n",
    "\n",
    "select_columns = [f for f, s in zip(train.columns, rfe.support_) if s] # rfe.support_ [True ... False ...]\n",
    "print(select_columns)\n",
    "new_train = train[select_columns]\n",
    "new_test = test[select_columns]\n",
    "\n",
    "# Lasso回归\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso=Lasso(alpha=0.1)\n",
    "lasso.fit(new_train,target_train)\n",
    "#预测测试集和训练集结果\n",
    "y_pred_train=lasso.predict(new_train)\n",
    "\n",
    "y_pred_test=lasso.predict(new_test)\n",
    "\n",
    "#对比结果\n",
    "from sklearn.metrics import r2_score\n",
    "score_train=r2_score(y_pred_train,target_train)\n",
    "print(\"训练集结果：\",score_train)\n",
    "# score_test=r2_score(y_pred_test, target_test)\n",
    "# print(\"测试集结果：\",score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedded\n",
    "### 基于惩罚项的特征选择法\n",
    "### Lasso(l1)和Ridge(l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[ 59  61  36 172  23 135  30  26  28 113  82  79 171 134  33  15   7   2\n 106 136  70 169  13  11  34  77  22  58   1   4  20  84   3 133 150 114\n  38  55 154  42 118  10  89   8 143 102  47  25  18  71 120  97  50 158\n 140 145  14  93 147  91 165  86  75  60 122   0 137  83 129  95  87  63\n  45  76  74 159 123  69 112 148  53  51 155 146  54 110  52 103 144  67\n  72 121 162 126 108  90 139 157  85 128  73 105 119 141 166 130 164  94\n  92  44  99 163 101  65 127  64   6  46 100  98  56 109 111  96  68 104\n 125 156   5  12  88  49 161  43 107  48 168 138 124  66  57  19  39 115\n 151   9  27 160  37 116 152  40 132 142  32  17 153 117  41  21  16  78\n  35 167  31 131  29 170 149  24  80  62  81]\n[-3.20014469e+04 -3.20014469e+04 -3.06236331e+04 -2.19182583e+04\n -2.08844163e+04 -1.83712267e+04 -1.83138871e+04 -1.78092757e+04\n -1.75698741e+04 -1.61437180e+04 -1.31003230e+04 -9.41179339e+03\n -7.21280572e+03 -6.08500213e+03 -5.92573955e+03 -5.78230748e+03\n -4.30615421e+03 -3.55704693e+03 -3.06189874e+03 -2.18222619e+03\n -2.01023463e+03 -1.86108883e+03 -1.71147134e+03 -1.58158140e+03\n -1.42015143e+03 -1.41944936e+03 -1.19560282e+03 -1.09271733e+03\n -1.04534300e+03 -8.24666499e+02 -8.24661811e+02 -7.69803083e+02\n -7.49868659e+02 -7.29351472e+02 -4.83520448e+02 -4.83520445e+02\n -4.83520443e+02 -4.75926617e+02 -4.02377128e+02 -4.02377126e+02\n -4.02377125e+02 -3.71222500e+02 -2.71565328e+02 -2.66050916e+02\n -2.55413744e+02 -2.45879927e+02 -2.41711821e+02 -1.92826428e+02\n -1.59880433e+02 -8.40370794e+01 -6.47381199e+01 -3.83026241e+01\n -3.18506302e+01 -3.07039589e+01 -3.00302479e+01 -2.54747221e+01\n -2.32791326e+01 -1.99241344e+01 -1.58116862e+01 -1.21830999e+01\n -1.11286104e+01 -1.07144628e+01 -7.84292083e+00 -7.12610250e+00\n -5.54294464e+00 -3.47013956e+00 -3.43726913e+00 -2.69509074e+00\n -2.40136020e+00 -2.04180351e+00 -1.48903468e+00 -1.25442871e+00\n -3.96012157e-01 -3.88800115e-01 -2.66202559e-01 -2.20629481e-01\n -9.75569049e-02 -8.40569706e-02 -7.90061748e-02 -7.81774516e-02\n -4.68750855e-02 -3.05323766e-02 -2.52677124e-02 -1.61230296e-02\n -1.40476041e-02 -1.36298517e-02 -1.16100721e-02 -2.94653598e-04\n -9.17216299e-05 -3.60008247e-05 -2.33436920e-05 -8.00959673e-06\n  8.76863515e-06  3.97440372e-05  4.63328693e-05  9.80117975e-05\n  2.37044477e-04  2.61072594e-04  4.09345356e-04  2.47904159e-02\n  2.57582330e-02  3.60269335e-02  4.61448333e-02  6.41624617e-02\n  1.24721059e-01  1.59909684e-01  1.85404759e-01  1.00120270e+00\n  1.13316567e+00  1.69337484e+00  2.65875959e+00  3.69450113e+00\n  3.98914671e+00  4.64636856e+00  5.92551325e+00  6.77676855e+00\n  8.97498929e+00  9.46019259e+00  9.99824594e+00  1.16589544e+01\n  1.44257015e+01  1.79895234e+01  2.53591132e+01  2.53699481e+01\n  2.67868272e+01  4.26102627e+01  4.73301759e+01  8.37468054e+01\n  1.18306534e+02  1.54253900e+02  1.68295871e+02  1.84243538e+02\n  1.90021695e+02  2.30443719e+02  2.31452053e+02  2.53600310e+02\n  3.03878856e+02  3.15282264e+02  4.15950603e+02  4.32437294e+02\n  6.90708562e+02  7.24009330e+02  7.91594030e+02  7.91594030e+02\n  7.91594031e+02  1.05191876e+03  1.08347314e+03  1.49636321e+03\n  1.75686729e+03  1.84807539e+03  1.84807540e+03  1.84807540e+03\n  1.98585964e+03  2.02432840e+03  2.57497609e+03  3.33758670e+03\n  6.77438692e+03  6.77438692e+03  6.77438692e+03  7.43807512e+03\n  9.56081964e+03  1.15810270e+04  1.17746107e+04  1.19864360e+04\n  1.30702413e+04  1.51483128e+04  1.62713953e+04  1.63645549e+04\n  1.77231536e+04  1.77241240e+04  2.43846028e+04  5.09925911e+04\n  6.23855890e+04]\n训练集结果： -46.30798817319642\n"
    }
   ],
   "source": [
    "# Embedded\n",
    "# 基于惩罚项的特征选择法\n",
    "# Lasso(l1)和Ridge(l2)\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge = Ridge(alpha=5)\n",
    "ridge.fit(train,target_train)\n",
    "\n",
    "Ridge(alpha=5, copy_X=True, fit_intercept=True, max_iter=None, normalize=False,\n",
    "      random_state=None, solver='auto', tol=0.001)\n",
    "\n",
    "# 特征系数排序\n",
    "coefSort = ridge.coef_.argsort()\n",
    "print(coefSort)\n",
    "\n",
    "\n",
    "# 特征系数\n",
    "featureCoefSore=ridge.coef_[coefSort]\n",
    "print(featureCoefSore)\n",
    "\n",
    "\n",
    "select_columns = [f for f, s in zip(train.columns, featureCoefSore) if abs(s)> 0.0000005 ] \n",
    "# 选择绝对值大于0.0000005的特征\n",
    "\n",
    "new_train = train[select_columns]\n",
    "new_test = test[select_columns]\n",
    "# Lasso回归\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso=Lasso(alpha=0.1)\n",
    "lasso.fit(new_train,target_train)\n",
    "#预测测试集和训练集结果\n",
    "y_pred_train=lasso.predict(new_train)\n",
    "\n",
    "y_pred_test=lasso.predict(new_test)\n",
    "\n",
    "#对比结果\n",
    "from sklearn.metrics import r2_score\n",
    "score_train=r2_score(y_pred_train,target_train)\n",
    "print(\"训练集结果：\",score_train)\n",
    "# score_test=r2_score(y_pred_test, target_test)\n",
    "# print(\"测试集结果：\",score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基于树模型的特征选择法\n",
    "### 随机森林 平均不纯度减少（mean decrease impurity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Features sorted by their score:\n[(0.1836, 'area'), (0.1394, 'count_communityName_totalFloor'), (0.0884, 'remainNewNum_houseDecoration_cluster_mean'), (0.0778, 'month'), (0.076, 'Room'), (0.0743, 'all_SchoolNum_totalFloor_cluster_mean'), (0.064, 'houseDecoration'), (0.0621, 'all_hospitalNum_houseDecoration_cluster_mean'), (0.0565, 'newWorkers_communityName_cluster_mean'), (0.0465, 'Room_Bath'), (0.0342, 'houseFloor'), (0.0329, 'all_SchoolNum'), (0.0204, 'remainNewNum_communityName_cluster_mean'), (0.0187, 'pv'), (0.0085, 'lookNum'), (0.0059, 'tradeMeanPrice'), (0.0041, 'tradeMeanPrice_communityName_cluster_mean'), (0.0032, 'tradeSecNum_communityName_cluster_mean'), (0.0003, 'count_communityName_totalTradeMoney'), (0.0003, 'count_buildYear'), (0.0002, 'tradeNewMeanPrice_region_cluster_mean'), (0.0002, 'tradeNewMeanPrice_communityName_cluster_mean'), (0.0002, 'totalNewTradeMoney'), (0.0002, 'totalNewTradeArea'), (0.0002, 'saleSecHouseNum'), (0.0002, 'newWorkers'), (0.0002, 'com_area_mean'), (0.0001, 'tradeSecNum'), (0.0001, 'tradeNewNum'), (0.0001, 'tradeNewMeanPrice_buildYear_cluster_mean'), (0.0001, 'tradeMeanPrice_plate_cluster_mean'), (0.0001, 'plate'), (0.0001, 'houseToward'), (0.0001, 'Hall'), (0.0, 'uv'), (0.0, 'trainsportNum_totalFloor_cluster_mean'), (0.0, 'trainsportNum_region_cluster_mean'), (0.0, 'trainsportNum_ratio'), (0.0, 'trainsportNum_plate_cluster_mean'), (0.0, 'trainsportNum_houseDecoration_cluster_mean'), (0.0, 'trainsportNum_communityName_cluster_mean'), (0.0, 'trainsportNum_buildYear_cluster_mean'), (0.0, 'trainsportNum'), (0.0, 'tradeSecNum_totalFloor_cluster_mean'), (0.0, 'tradeSecNum_region_cluster_mean'), (0.0, 'tradeSecNum_plate_cluster_mean'), (0.0, 'tradeSecNum_houseDecoration_cluster_mean'), (0.0, 'tradeSecNum_buildYear_cluster_mean'), (0.0, 'tradeNewNum_totalFloor_cluster_mean'), (0.0, 'tradeNewNum_region_cluster_mean'), (0.0, 'tradeNewNum_plate_cluster_mean'), (0.0, 'tradeNewNum_houseDecoration_cluster_mean'), (0.0, 'tradeNewNum_communityName_cluster_mean'), (0.0, 'tradeNewNum_buildYear_cluster_mean'), (0.0, 'tradeNewMeanPrice_totalFloor_cluster_mean'), (0.0, 'tradeNewMeanPrice_plate_cluster_mean'), (0.0, 'tradeNewMeanPrice_houseDecoration_cluster_mean'), (0.0, 'tradeNewMeanPrice'), (0.0, 'tradeMeanPrice_totalFloor_cluster_mean'), (0.0, 'tradeMeanPrice_region_cluster_mean'), (0.0, 'tradeMeanPrice_houseDecoration_cluster_mean'), (0.0, 'tradeMeanPrice_buildYear_cluster_mean'), (0.0, 'tradeLandNum'), (0.0, 'tradeLandArea'), (0.0, 'totalWorkers_totalFloor_cluster_mean'), (0.0, 'totalWorkers_region_cluster_mean'), (0.0, 'totalWorkers_plate_cluster_mean'), (0.0, 'totalWorkers_houseDecoration_cluster_mean'), (0.0, 'totalWorkers_communityName_cluster_mean'), (0.0, 'totalWorkers_buildYear_cluster_mean'), (0.0, 'totalWorkers'), (0.0, 'totalTradeMoney'), (0.0, 'totalTradeArea'), (0.0, 'totalNewTradeMoney_totalFloor_cluster_mean'), (0.0, 'totalNewTradeMoney_region_cluster_mean'), (0.0, 'totalNewTradeMoney_plate_cluster_mean'), (0.0, 'totalNewTradeMoney_houseDecoration_cluster_mean'), (0.0, 'totalNewTradeMoney_communityName_cluster_mean'), (0.0, 'totalNewTradeMoney_buildYear_cluster_mean'), (0.0, 'totalNewTradeArea_totalFloor_cluster_mean'), (0.0, 'totalNewTradeArea_region_cluster_mean'), (0.0, 'totalNewTradeArea_plate_cluster_mean'), (0.0, 'totalNewTradeArea_houseDecoration_cluster_mean'), (0.0, 'totalNewTradeArea_communityName_cluster_mean'), (0.0, 'totalNewTradeArea_buildYear_cluster_mean'), (0.0, 'totalFloor'), (0.0, 'supplyNewNum'), (0.0, 'supplyLandNum'), (0.0, 'supplyLandArea'), (0.0, 'sale_ratio'), (0.0, 'sale_newworker_differ'), (0.0, 'residentPopulation_totalFloor_cluster_mean'), (0.0, 'residentPopulation_region_cluster_mean'), (0.0, 'residentPopulation_plate_cluster_mean'), (0.0, 'residentPopulation_houseDecoration_cluster_mean'), (0.0, 'residentPopulation_communityName_cluster_mean'), (0.0, 'residentPopulation_buildYear_cluster_mean'), (0.0, 'residentPopulation'), (0.0, 'rentType'), (0.0, 'remainNewNum_totalFloor_cluster_mean'), (0.0, 'remainNewNum_region_cluster_mean'), (0.0, 'remainNewNum_plate_cluster_mean'), (0.0, 'remainNewNum_buildYear_cluster_mean'), (0.0, 'remainNewNum'), (0.0, 'region'), (0.0, 'plate_year_std'), (0.0, 'plate_price_std'), (0.0, 'plate_price_mean'), (0.0, 'plate_area_std'), (0.0, 'plate_area_mean'), (0.0, 'other_ratio'), (0.0, 'otherNum_totalFloor_cluster_mean'), (0.0, 'otherNum_region_cluster_mean'), (0.0, 'otherNum_plate_cluster_mean'), (0.0, 'otherNum_houseDecoration_cluster_mean'), (0.0, 'otherNum_communityName_cluster_mean'), (0.0, 'otherNum_buildYear_cluster_mean'), (0.0, 'otherNum'), (0.0, 'newWorkers_totalFloor_cluster_mean'), (0.0, 'newWorkers_region_cluster_mean'), (0.0, 'newWorkers_plate_cluster_mean'), (0.0, 'newWorkers_houseDecoration_cluster_mean'), (0.0, 'newWorkers_buildYear_cluster_mean'), (0.0, 'lookNum_totalFloor_cluster_mean'), (0.0, 'lookNum_region_cluster_mean'), (0.0, 'lookNum_plate_cluster_mean'), (0.0, 'lookNum_houseDecoration_cluster_mean'), (0.0, 'lookNum_communityName_cluster_mean'), (0.0, 'lookNum_buildYear_cluster_mean'), (0.0, 'landTotalPrice_totalFloor_cluster_mean'), (0.0, 'landTotalPrice_region_cluster_mean'), (0.0, 'landTotalPrice_plate_cluster_mean'), (0.0, 'landTotalPrice_houseDecoration_cluster_mean'), (0.0, 'landTotalPrice_communityName_cluster_mean'), (0.0, 'landTotalPrice_buildYear_cluster_mean'), (0.0, 'landTotalPrice'), (0.0, 'landMeanPrice_totalFloor_cluster_mean'), (0.0, 'landMeanPrice_region_cluster_mean'), (0.0, 'landMeanPrice_plate_cluster_mean'), (0.0, 'landMeanPrice_houseDecoration_cluster_mean'), (0.0, 'landMeanPrice_communityName_cluster_mean'), (0.0, 'landMeanPrice_buildYear_cluster_mean'), (0.0, 'landMeanPrice'), (0.0, 'count_totalFloor'), (0.0, 'count_communityName_newWorkers'), (0.0, 'count_communityName'), (0.0, 'communityName'), (0.0, 'comm_price_std'), (0.0, 'comm_price_mean'), (0.0, 'comm_plate_year_diff'), (0.0, 'com_area_std'), (0.0, 'com_all_mall'), (0.0, 'cluster'), (0.0, 'buildYear'), (0.0, 'all_mall_totalFloor_cluster_mean'), (0.0, 'all_mall_region_cluster_mean'), (0.0, 'all_mall_plate_cluster_mean'), (0.0, 'all_mall_houseDecoration_cluster_mean'), (0.0, 'all_mall_communityName_cluster_mean'), (0.0, 'all_mall_buildYear_cluster_mean'), (0.0, 'all_mall'), (0.0, 'all_hospitalNum_totalFloor_cluster_mean'), (0.0, 'all_hospitalNum_region_cluster_mean'), (0.0, 'all_hospitalNum_plate_cluster_mean'), (0.0, 'all_hospitalNum_communityName_cluster_mean'), (0.0, 'all_hospitalNum_buildYear_cluster_mean'), (0.0, 'all_hospitalNum'), (0.0, 'all_SchoolNum_region_cluster_mean'), (0.0, 'all_SchoolNum_plate_cluster_mean'), (0.0, 'all_SchoolNum_houseDecoration_cluster_mean'), (0.0, 'all_SchoolNum_communityName_cluster_mean'), (0.0, 'all_SchoolNum_buildYear_cluster_mean'), (0.0, 'Bath')]\n训练集结果： -81.38294473222608\n"
    }
   ],
   "source": [
    "# Embedded\n",
    "# 基于树模型的特征选择法\n",
    "# 随机森林 平均不纯度减少（mean decrease impurity\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor()\n",
    "# 训练随机森林模型，并通过feature_importances_属性获取每个特征的重要性分数。rf = RandomForestRegressor()\n",
    "rf.fit(train,target_train)\n",
    "print(\"Features sorted by their score:\")\n",
    "print(sorted(zip(map(lambda x: round(x, 4), rf.feature_importances_), train.columns),\n",
    "             reverse=True))\n",
    "\n",
    "select_columns = [f for f, s in zip(train.columns, rf.feature_importances_) if abs(s)> 0.00005 ] \n",
    "# 选择绝对值大于0.00005的特征\n",
    "\n",
    "new_train = train[select_columns]\n",
    "new_test = test[select_columns]\n",
    "\n",
    "# Lasso回归\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso=Lasso(alpha=0.1)\n",
    "lasso.fit(new_train,target_train)\n",
    "#预测测试集和训练集结果\n",
    "y_pred_train=lasso.predict(new_train)\n",
    "\n",
    "y_pred_test=lasso.predict(new_test)\n",
    "\n",
    "#对比结果\n",
    "from sklearn.metrics import r2_score\n",
    "score_train=r2_score(y_pred_train,target_train)\n",
    "print(\"训练集结果：\",score_train)\n",
    "# score_test=r2_score(y_pred_test, target_test)\n",
    "# print(\"测试集结果：\",score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6-final"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
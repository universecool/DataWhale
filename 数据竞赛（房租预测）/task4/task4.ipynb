{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  任务4 模型选择(3天)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 以lightGBM为例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "oss: -0.9039081010472629]nb_trees\n 19%|█▉        | 94/500 [3:52:15<14:12:25, 125.97s/trial, best loss: -0.9039081010472629]3737\n 19%|█▉        | 94/500 [3:52:15<14:12:25, 125.97s/trial, best loss: -0.9039081010472629]nb_trees=3737 val_loss={'rmse': 722.4431968910534}\n 19%|█▉        | 94/500 [3:52:15<14:12:25, 125.97s/trial, best loss: -0.9039081010472629]nb_trees\n 19%|█▉        | 94/500 [3:52:57<14:12:25, 125.97s/trial, best loss: -0.9039081010472629]3720\n 19%|█▉        | 94/500 [3:52:57<14:12:25, 125.97s/trial, best loss: -0.9039081010472629]nb_trees=3720 val_loss={'rmse': 746.6065792214056}\n 19%|█▉        | 94/500 [3:52:57<14:12:25, 125.97s/trial, best loss: -0.9039081010472629]nb_trees\n 19%|█▉        | 94/500 [3:53:38<14:12:25, 125.97s/trial, best loss: -0.9039081010472629]3563\n 19%|█▉        | 94/500 [3:53:38<14:12:25, 125.97s/trial, best loss: -0.9039081010472629]nb_trees=3563 val_loss={'rmse': 751.1225266299465}\n 19%|█▉        | 94/500 [3:53:38<14:12:25, 125.97s/trial, best loss: -0.9039081010472629]val_r2_score=0.9030956516606745\n 19%|█▉        | 95/500 [3:53:40<14:10:21, 125.98s/trial, best loss: -0.9039081010472629]\nLightGBM objective call #96 cur_best_score=0.90391\n 19%|█▉        | 95/500 [3:53:40<14:10:21, 125.98s/trial, best loss: -0.9039081010472629]Params: bagging_fraction=0.798996070501109 bagging_freq=6.0 feature_fraction=0.8021424147056708 lambda_l1=0.05711373122263286 lambda_l2=9.71551896052178 learning_rate=0.007277684301682105 max_bin=117.0 min_data_in_leaf=92.0 min_sum_hessian_in_leaf=3.6241707220397843 num_leaves=64.0\n 19%|█▉        | 95/500 [3:53:40<14:10:21, 125.98s/trial, best loss: -0.9039081010472629]nb_trees\n 19%|█▉        | 95/500 [3:54:21<14:10:21, 125.98s/trial, best loss: -0.9039081010472629]4716\n 19%|█▉        | 95/500 [3:54:21<14:10:21, 125.98s/trial, best loss: -0.9039081010472629]nb_trees=4716 val_loss={'rmse': 725.5367883050934}\n 19%|█▉        | 95/500 [3:54:21<14:10:21, 125.98s/trial, best loss: -0.9039081010472629]nb_trees\n 19%|█▉        | 95/500 [3:55:06<14:10:21, 125.98s/trial, best loss: -0.9039081010472629]4860\n 19%|█▉        | 95/500 [3:55:06<14:10:21, 125.98s/trial, best loss: -0.9039081010472629]nb_trees=4860 val_loss={'rmse': 748.9753664385016}\n 19%|█▉        | 95/500 [3:55:06<14:10:21, 125.98s/trial, best loss: -0.9039081010472629]nb_trees\n 19%|█▉        | 95/500 [3:55:50<14:10:21, 125.98s/trial, best loss: -0.9039081010472629]4752\n 19%|█▉        | 95/500 [3:55:50<14:10:21, 125.98s/trial, best loss: -0.9039081010472629]nb_trees=4752 val_loss={'rmse': 750.624443717525}\n 19%|█▉        | 95/500 [3:55:50<14:10:21, 125.98s/trial, best loss: -0.9039081010472629]val_r2_score=0.902858485778493\n 19%|█▉        | 96/500 [3:55:53<14:20:40, 127.82s/trial, best loss: -0.9039081010472629]\nLightGBM objective call #97 cur_best_score=0.90391\n 19%|█▉        | 96/500 [3:55:53<14:20:40, 127.82s/trial, best loss: -0.9039081010472629]Params: bagging_fraction=0.8480865323315723 bagging_freq=12.0 feature_fraction=0.9312845542067183 lambda_l1=7.93579753727654 lambda_l2=4.637843571451212 learning_rate=0.0055139042527241455 max_bin=124.0 min_data_in_leaf=56.0 min_sum_hessian_in_leaf=3.2572992340759863 num_leaves=29.0\n 19%|█▉        | 96/500 [3:55:53<14:20:40, 127.82s/trial, best loss: -0.9039081010472629]nb_trees\n 19%|█▉        | 96/500 [3:56:42<14:20:40, 127.82s/trial, best loss: -0.9039081010472629]9015\n 19%|█▉        | 96/500 [3:56:42<14:20:40, 127.82s/trial, best loss: -0.9039081010472629]nb_trees=9015 val_loss={'rmse': 726.2385531149904}\n 19%|█▉        | 96/500 [3:56:42<14:20:40, 127.82s/trial, best loss: -0.9039081010472629]nb_trees\n 19%|█▉        | 96/500 [3:57:38<14:20:40, 127.82s/trial, best loss: -0.9039081010472629]9647\n 19%|█▉        | 96/500 [3:57:38<14:20:40, 127.82s/trial, best loss: -0.9039081010472629]nb_trees=9647 val_loss={'rmse': 750.4385181982738}\n 19%|█▉        | 96/500 [3:57:38<14:20:40, 127.82s/trial, best loss: -0.9039081010472629]nb_trees\n 19%|█▉        | 96/500 [3:58:33<14:20:40, 127.82s/trial, best loss: -0.9039081010472629]9289\n 19%|█▉        | 96/500 [3:58:33<14:20:40, 127.82s/trial, best loss: -0.9039081010472629]nb_trees=9289 val_loss={'rmse': 755.3497030979132}\n 19%|█▉        | 96/500 [3:58:33<14:20:40, 127.82s/trial, best loss: -0.9039081010472629]val_r2_score=0.9019881391506057\n 19%|█▉        | 97/500 [3:58:36<15:30:52, 138.59s/trial, best loss: -0.9039081010472629]\nLightGBM objective call #98 cur_best_score=0.90391\n 19%|█▉        | 97/500 [3:58:36<15:30:52, 138.59s/trial, best loss: -0.9039081010472629]Params: bagging_fraction=0.9784428117591494 bagging_freq=14.0 feature_fraction=0.7592190320099831 lambda_l1=6.832888310495419 lambda_l2=7.590989768064399 learning_rate=0.005130750515634658 max_bin=111.0 min_data_in_leaf=25.0 min_sum_hessian_in_leaf=4.300741229628395 num_leaves=24.0\n 19%|█▉        | 97/500 [3:58:36<15:30:52, 138.59s/trial, best loss: -0.9039081010472629]nb_trees\n 19%|█▉        | 97/500 [3:59:21<15:30:52, 138.59s/trial, best loss: -0.9039081010472629]10000\n 19%|█▉        | 97/500 [3:59:21<15:30:52, 138.59s/trial, best loss: -0.9039081010472629]nb_trees=10000 val_loss={'rmse': 726.6662205883606}\n 19%|█▉        | 97/500 [3:59:21<15:30:52, 138.59s/trial, best loss: -0.9039081010472629]nb_trees\n 19%|█▉        | 97/500 [4:00:09<15:30:52, 138.59s/trial, best loss: -0.9039081010472629]9998\n 19%|█▉        | 97/500 [4:00:09<15:30:52, 138.59s/trial, best loss: -0.9039081010472629]nb_trees=9998 val_loss={'rmse': 750.8412497221663}\n 19%|█▉        | 97/500 [4:00:09<15:30:52, 138.59s/trial, best loss: -0.9039081010472629]nb_trees\n 19%|█▉        | 97/500 [4:00:57<15:30:52, 138.59s/trial, best loss: -0.9039081010472629]10000\n 19%|█▉        | 97/500 [4:00:57<15:30:52, 138.59s/trial, best loss: -0.9039081010472629]nb_trees=10000 val_loss={'rmse': 755.7514480646574}\n 19%|█▉        | 97/500 [4:00:57<15:30:52, 138.59s/trial, best loss: -0.9039081010472629]val_r2_score=0.9013281035694513\n 20%|█▉        | 98/500 [4:01:00<15:39:00, 140.15s/trial, best loss: -0.9039081010472629]\nLightGBM objective call #99 cur_best_score=0.90391\n 20%|█▉        | 98/500 [4:01:00<15:39:00, 140.15s/trial, best loss: -0.9039081010472629]Params: bagging_fraction=0.8224952523805099 bagging_freq=1.0 feature_fraction=0.8864579776339823 lambda_l1=9.29988841863645 lambda_l2=5.730509336589764 learning_rate=0.004732436090130299 max_bin=108.0 min_data_in_leaf=63.0 min_sum_hessian_in_leaf=9.465335339341982 num_leaves=55.0\n 20%|█▉        | 98/500 [4:01:00<15:39:00, 140.15s/trial, best loss: -0.9039081010472629]nb_trees\n 20%|█▉        | 98/500 [4:02:02<15:39:00, 140.15s/trial, best loss: -0.9039081010472629]7681\n 20%|█▉        | 98/500 [4:02:02<15:39:00, 140.15s/trial, best loss: -0.9039081010472629]nb_trees=7681 val_loss={'rmse': 721.8839802888126}\n 20%|█▉        | 98/500 [4:02:02<15:39:00, 140.15s/trial, best loss: -0.9039081010472629]nb_trees\n 20%|█▉        | 98/500 [4:03:10<15:39:00, 140.15s/trial, best loss: -0.9039081010472629]7862\n 20%|█▉        | 98/500 [4:03:10<15:39:00, 140.15s/trial, best loss: -0.9039081010472629]nb_trees=7862 val_loss={'rmse': 746.0455962507389}\n 20%|█▉        | 98/500 [4:03:10<15:39:00, 140.15s/trial, best loss: -0.9039081010472629]nb_trees\n 20%|█▉        | 98/500 [4:04:09<15:39:00, 140.15s/trial, best loss: -0.9039081010472629]6932\n 20%|█▉        | 98/500 [4:04:09<15:39:00, 140.15s/trial, best loss: -0.9039081010472629]nb_trees=6932 val_loss={'rmse': 749.2625188545185}\n 20%|█▉        | 98/500 [4:04:10<15:39:00, 140.15s/trial, best loss: -0.9039081010472629]val_r2_score=0.903538498637273\n 20%|█▉        | 99/500 [4:04:13<17:22:44, 156.02s/trial, best loss: -0.9039081010472629]\nLightGBM objective call #100 cur_best_score=0.90391\n 20%|█▉        | 99/500 [4:04:13<17:22:44, 156.02s/trial, best loss: -0.9039081010472629]Params: bagging_fraction=0.8396696685162488 bagging_freq=2.0 feature_fraction=0.8168191909926001 lambda_l1=8.29707384102665 lambda_l2=6.255592600143206 learning_rate=0.00938353661865467 max_bin=94.0 min_data_in_leaf=16.0 min_sum_hessian_in_leaf=3.0650750671807905 num_leaves=51.0\n 20%|█▉        | 99/500 [4:04:13<17:22:44, 156.02s/trial, best loss: -0.9039081010472629]nb_trees\n 20%|█▉        | 99/500 [4:04:42<17:22:44, 156.02s/trial, best loss: -0.9039081010472629]4174\n 20%|█▉        | 99/500 [4:04:42<17:22:44, 156.02s/trial, best loss: -0.9039081010472629]nb_trees=4174 val_loss={'rmse': 721.6322322719365}\n 20%|█▉        | 99/500 [4:04:42<17:22:44, 156.02s/trial, best loss: -0.9039081010472629]nb_trees\n 20%|█▉        | 99/500 [4:05:17<17:22:44, 156.02s/trial, best loss: -0.9039081010472629]4952\n 20%|█▉        | 99/500 [4:05:17<17:22:44, 156.02s/trial, best loss: -0.9039081010472629]nb_trees=4952 val_loss={'rmse': 744.3880946090983}\n 20%|█▉        | 99/500 [4:05:17<17:22:44, 156.02s/trial, best loss: -0.9039081010472629]nb_trees\n 20%|█▉        | 99/500 [4:05:46<17:22:44, 156.02s/trial, best loss: -0.9039081010472629]3930\n 20%|█▉        | 99/500 [4:05:46<17:22:44, 156.02s/trial, best loss: -0.9039081010472629]nb_trees=3930 val_loss={'rmse': 751.7886130835261}\n 20%|█▉        | 99/500 [4:05:46<17:22:44, 156.02s/trial, best loss: -0.9039081010472629]val_r2_score=0.9032516684537465\n 20%|██        | 100/500 [4:05:48<15:17:00, 137.55s/trial, best loss: -0.9039081010472629]\nLightGBM objective call #101 cur_best_score=0.90391\n 20%|██        | 100/500 [4:05:48<15:17:00, 137.55s/trial, best loss: -0.9039081010472629]Params: bagging_fraction=0.7923147203813109 bagging_freq=7.0 feature_fraction=0.8469962440430928 lambda_l1=5.572103080215146 lambda_l2=5.193760662095622 learning_rate=0.007596265421882105 max_bin=178.0 min_data_in_leaf=75.0 min_sum_hessian_in_leaf=4.098266883999198 num_leaves=42.0\n 20%|██        | 100/500 [4:05:48<15:17:00, 137.55s/trial, best loss: -0.9039081010472629]nb_trees\n 20%|██        | 100/500 [4:06:31<15:17:00, 137.55s/trial, best loss: -0.9039081010472629]5978\n 20%|██        | 100/500 [4:06:31<15:17:00, 137.55s/trial, best loss: -0.9039081010472629]nb_trees=5978 val_loss={'rmse': 723.356675426535}\n 20%|██        | 100/500 [4:06:31<15:17:00, 137.55s/trial, best loss: -0.9039081010472629]nb_trees\n 20%|██        | 100/500 [4:07:11<15:17:00, 137.55s/trial, best loss: -0.9039081010472629]5251\n 20%|██        | 100/500 [4:07:11<15:17:00, 137.55s/trial, best loss: -0.9039081010472629]nb_trees=5251 val_loss={'rmse': 747.9746692258366}\n 20%|██        | 100/500 [4:07:11<15:17:00, 137.55s/trial, best loss: -0.9039081010472629]nb_trees\n 20%|██        | 100/500 [4:07:48<15:17:00, 137.55s/trial, best loss: -0.9039081010472629]4802\n 20%|██        | 100/500 [4:07:48<15:17:00, 137.55s/trial, best loss: -0.9039081010472629]nb_trees=4802 val_loss={'rmse': 754.9936250315371}\n 20%|██        | 100/500 [4:07:48<15:17:00, 137.55s/trial, best loss: -0.9039081010472629]val_r2_score=0.9027559922677295\n 20%|██        | 101/500 [4:07:50<14:44:41, 133.04s/trial, best loss: -0.9039081010472629]\nLightGBM objective call #102 cur_best_score=0.90391\n 20%|██        | 101/500 [4:07:50<14:44:41, 133.04s/trial, best loss: -0.9039081010472629]Params: bagging_fraction=0.7716215577246176 bagging_freq=10.0 feature_fraction=0.7647408549158814 lambda_l1=9.79978418261492 lambda_l2=3.524639873791142 learning_rate=0.005770988016021537 max_bin=90.0 min_data_in_leaf=10.0 min_sum_hessian_in_leaf=3.8384295375094095 num_leaves=45.0\n 20%|██        | 101/500 [4:07:50<14:44:41, 133.04s/trial, best loss: -0.9039081010472629]nb_trees\n 20%|██        | 101/500 [4:08:39<14:44:41, 133.04s/trial, best loss: -0.9039081010472629]8250\n 20%|██        | 101/500 [4:08:39<14:44:41, 133.04s/trial, best loss: -0.9039081010472629]nb_trees=8250 val_loss={'rmse': 720.9843201988348}\n 20%|██        | 101/500 [4:08:39<14:44:41, 133.04s/trial, best loss: -0.9039081010472629]nb_trees\n 20%|██        | 101/500 [4:09:24<14:44:41, 133.04s/trial, best loss: -0.9039081010472629]6736\n 20%|██        | 101/500 [4:09:24<14:44:41, 133.04s/trial, best loss: -0.9039081010472629]nb_trees=6736 val_loss={'rmse': 745.8673736505376}\n 20%|██        | 101/500 [4:09:24<14:44:41, 133.04s/trial, best loss: -0.9039081010472629]nb_trees\n 20%|██        | 101/500 [4:10:00<14:44:41, 133.04s/trial, best loss: -0.9039081010472629]5486\n 20%|██        | 101/500 [4:10:00<14:44:41, 133.04s/trial, best loss: -0.9039081010472629]nb_trees=5486 val_loss={'rmse': 751.6823789634267}\n 20%|██        | 101/500 [4:10:00<14:44:41, 133.04s/trial, best loss: -0.9039081010472629]val_r2_score=0.9029598431516408\n 20%|██        | 102/500 [4:10:02<14:40:09, 132.69s/trial, best loss: -0.9039081010472629]\nLightGBM objective call #103 cur_best_score=0.90391\n 20%|██        | 102/500 [4:10:02<14:40:09, 132.69s/trial, best loss: -0.9039081010472629]Params: bagging_fraction=0.8581729582887169 bagging_freq=4.0 feature_fraction=0.9019365627949429 lambda_l1=7.557678216664745 lambda_l2=4.769391523852871 learning_rate=0.001845785659548415 max_bin=101.0 min_data_in_leaf=60.0 min_sum_hessian_in_leaf=5.112180353876666 num_leaves=68.0\n 20%|██        | 102/500 [4:10:02<14:40:09, 132.69s/trial, best loss: -0.9039081010472629]nb_trees\n 20%|██        | 102/500 [4:11:33<14:40:09, 132.69s/trial, best loss: -0.9039081010472629]9987\n 20%|██        | 102/500 [4:11:33<14:40:09, 132.69s/trial, best loss: -0.9039081010472629]nb_trees=9987 val_loss={'rmse': 724.8661050195765}\n 20%|██        | 102/500 [4:11:33<14:40:09, 132.69s/trial, best loss: -0.9039081010472629]nb_trees\n 20%|██        | 102/500 [4:13:12<14:40:09, 132.69s/trial, best loss: -0.9039081010472629]10000\n 20%|██        | 102/500 [4:13:12<14:40:09, 132.69s/trial, best loss: -0.9039081010472629]nb_trees=10000 val_loss={'rmse': 751.5333991223532}\n 20%|██        | 102/500 [4:13:13<14:40:09, 132.69s/trial, best loss: -0.9039081010472629]nb_trees\n 20%|██        | 102/500 [4:14:52<14:40:09, 132.69s/trial, best loss: -0.9039081010472629]10000\n 20%|██        | 102/500 [4:14:52<14:40:09, 132.69s/trial, best loss: -0.9039081010472629]nb_trees=10000 val_loss={'rmse': 754.210152956452}\n 20%|██        | 102/500 [4:14:52<14:40:09, 132.69s/trial, best loss: -0.9039081010472629]val_r2_score=0.9015646012113173\n 21%|██        | 103/500 [4:14:59<20:04:48, 182.09s/trial, best loss: -0.9039081010472629]\nLightGBM objective call #104 cur_best_score=0.90391\n 21%|██        | 103/500 [4:14:59<20:04:48, 182.09s/trial, best loss: -0.9039081010472629]Params: bagging_fraction=0.9485298919445724 bagging_freq=6.0 feature_fraction=0.7808015146007993 lambda_l1=3.7603068244381426 lambda_l2=2.1405662857802996 learning_rate=0.007085402657791227 max_bin=146.0 min_data_in_leaf=34.0 min_sum_hessian_in_leaf=4.753856171678834 num_leaves=90.0\n 21%|██        | 103/500 [4:14:59<20:04:48, 182.09s/trial, best loss: -0.9039081010472629]nb_trees\n 21%|██        | 103/500 [4:15:43<20:04:48, 182.09s/trial, best loss: -0.9039081010472629]3837\n 21%|██        | 103/500 [4:15:43<20:04:48, 182.09s/trial, best loss: -0.9039081010472629]nb_trees=3837 val_loss={'rmse': 723.3442894424152}\n 21%|██        | 103/500 [4:15:43<20:04:48, 182.09s/trial, best loss: -0.9039081010472629]nb_trees\n 21%|██        | 103/500 [4:16:34<20:04:48, 182.09s/trial, best loss: -0.9039081010472629]4432\n 21%|██        | 103/500 [4:16:34<20:04:48, 182.09s/trial, best loss: -0.9039081010472629]nb_trees=4432 val_loss={'rmse': 745.9662429418021}\n 21%|██        | 103/500 [4:16:34<20:04:48, 182.09s/trial, best loss: -0.9039081010472629]nb_trees\n 21%|██        | 103/500 [4:17:11<20:04:48, 182.09s/trial, best loss: -0.9039081010472629]2905\n 21%|██        | 103/500 [4:17:11<20:04:48, 182.09s/trial, best loss: -0.9039081010472629]nb_trees=2905 val_loss={'rmse': 754.2397825932319}\n 21%|██        | 103/500 [4:17:11<20:04:48, 182.09s/trial, best loss: -0.9039081010472629]val_r2_score=0.9027512668212937\n 21%|██        | 104/500 [4:17:12<18:24:20, 167.32s/trial, best loss: -0.9039081010472629]\nLightGBM objective call #105 cur_best_score=0.90391\n 21%|██        | 104/500 [4:17:12<18:24:20, 167.32s/trial, best loss: -0.9039081010472629]Params: bagging_fraction=0.7833667750968673 bagging_freq=3.0 feature_fraction=0.8362451785952403 lambda_l1=6.183499277337109 lambda_l2=3.9202420963182982 learning_rate=0.008504822371427221 max_bin=134.0 min_data_in_leaf=84.0 min_sum_hessian_in_leaf=2.735099170309496 num_leaves=74.0\n 21%|██        | 104/500 [4:17:12<18:24:20, 167.32s/trial, best loss: -0.9039081010472629]nb_trees\n 21%|██        | 104/500 [4:17:50<18:24:20, 167.32s/trial, best loss: -0.9039081010472629]3786\n 21%|██        | 104/500 [4:17:50<18:24:20, 167.32s/trial, best loss: -0.9039081010472629]nb_trees=3786 val_loss={'rmse': 723.2663773089306}\n 21%|██        | 104/500 [4:17:50<18:24:20, 167.32s/trial, best loss: -0.9039081010472629]nb_trees\n 21%|██        | 104/500 [4:18:28<18:24:20, 167.32s/trial, best loss: -0.9039081010472629]3596\n 21%|██        | 104/500 [4:18:28<18:24:20, 167.32s/trial, best loss: -0.9039081010472629]nb_trees=3596 val_loss={'rmse': 748.8097440001501}\n 21%|██        | 104/500 [4:18:29<18:24:20, 167.32s/trial, best loss: -0.9039081010472629]nb_trees\n 21%|██        | 104/500 [4:19:03<18:24:20, 167.32s/trial, best loss: -0.9039081010472629]3006\n 21%|██        | 104/500 [4:19:03<18:24:20, 167.32s/trial, best loss: -0.9039081010472629]nb_trees=3006 val_loss={'rmse': 754.4031808754947}\n 21%|██        | 104/500 [4:19:03<18:24:20, 167.32s/trial, best loss: -0.9039081010472629]val_r2_score=0.902701816564743\n 21%|██        | 105/500 [4:19:05<16:33:02, 150.84s/trial, best loss: -0.9039081010472629]\nLightGBM objective call #106 cur_best_score=0.90391\n 21%|██        | 105/500 [4:19:05<16:33:02, 150.84s/trial, best loss: -0.9039081010472629]Params: bagging_fraction=0.763520801321511 bagging_freq=13.0 feature_fraction=0.7866033663866996 lambda_l1=7.282276522648753 lambda_l2=4.299636910302017 learning_rate=0.008203372235657388 max_bin=121.0 min_data_in_leaf=30.0 min_sum_hessian_in_leaf=2.4209823265212833 num_leaves=39.0\n 21%|██        | 105/500 [4:19:05<16:33:02, 150.84s/trial, best loss: -0.9039081010472629]nb_trees\n 21%|██        | 105/500 [4:19:34<16:33:02, 150.84s/trial, best loss: -0.9039081010472629]5031\n 21%|██        | 105/500 [4:19:34<16:33:02, 150.84s/trial, best loss: -0.9039081010472629]nb_trees=5031 val_loss={'rmse': 722.5723909012078}\n 21%|██        | 105/500 [4:19:34<16:33:02, 150.84s/trial, best loss: -0.9039081010472629]nb_trees\n 21%|██        | 105/500 [4:20:12<16:33:02, 150.84s/trial, best loss: -0.9039081010472629]6240\n 21%|██        | 105/500 [4:20:12<16:33:02, 150.84s/trial, best loss: -0.9039081010472629]nb_trees=6240 val_loss={'rmse': 745.8776738534856}\n 21%|██        | 105/500 [4:20:12<16:33:02, 150.84s/trial, best loss: -0.9039081010472629]nb_trees\n 21%|██        | 105/500 [4:20:39<16:33:02, 150.84s/trial, best loss: -0.9039081010472629]4106\n 21%|██        | 105/500 [4:20:39<16:33:02, 150.84s/trial, best loss: -0.9039081010472629]nb_trees=4106 val_loss={'rmse': 755.5921998926317}\n 21%|██        | 105/500 [4:20:39<16:33:02, 150.84s/trial, best loss: -0.9039081010472629]val_r2_score=0.902751125851365\n 21%|██        | 106/500 [4:20:40<14:41:09, 134.19s/trial, best loss: -0.9039081010472629]\nLightGBM objective call #107 cur_best_score=0.90391\n 21%|██        | 106/500 [4:20:40<14:41:09, 134.19s/trial, best loss: -0.9039081010472629]Params: bagging_fraction=0.9045349822236837 bagging_freq=8.0 feature_fraction=0.9541564085015297 lambda_l1=5.101991557573968 lambda_l2=6.826033315427554 learning_rate=0.0004747352159491522 max_bin=127.0 min_data_in_leaf=24.0 min_sum_hessian_in_leaf=3.496174289503724 num_leaves=49.0\n 21%|██        | 106/500 [4:20:40<14:41:09, 134.19s/trial, best loss: -0.9039081010472629]nb_trees\n 21%|██        | 106/500 [4:22:26<14:41:09, 134.19s/trial, best loss: -0.9039081010472629]10000\n 21%|██        | 106/500 [4:22:26<14:41:09, 134.19s/trial, best loss: -0.9039081010472629]nb_trees=10000 val_loss={'rmse': 797.6571975822208}\n 21%|██        | 106/500 [4:22:26<14:41:09, 134.19s/trial, best loss: -0.9039081010472629]"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import lightgbm as lgb\n",
    "import sklearn\n",
    "import numpy\n",
    "import hyperopt\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "import colorama\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "N_HYPEROPT_PROBES = 500\n",
    "HYPEROPT_ALGO = tpe.suggest  #  tpe.suggest OR hyperopt.rand.suggest\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "colorama.init()\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "def get_lgb_params(space):\n",
    "    lgb_params = dict()\n",
    "    lgb_params['boosting_type'] = space['boosting_type'] if 'boosting_type' in space else 'gbdt'\n",
    "    lgb_params['objective'] = 'regression'\n",
    "    lgb_params['metric'] = 'rmse'\n",
    "    lgb_params['learning_rate'] = space['learning_rate']\n",
    "    lgb_params['num_leaves'] = int(space['num_leaves'])\n",
    "    lgb_params['min_data_in_leaf'] = int(space['min_data_in_leaf'])\n",
    "    lgb_params['min_sum_hessian_in_leaf'] = space['min_sum_hessian_in_leaf']\n",
    "    lgb_params['max_depth'] = -1\n",
    "    lgb_params['lambda_l1'] = space['lambda_l1'] if 'lambda_l1' in space else 0.0\n",
    "    lgb_params['lambda_l2'] = space['lambda_l2'] if 'lambda_l2' in space else 0.0\n",
    "    lgb_params['max_bin'] = int(space['max_bin']) if 'max_bin' in space else 256\n",
    "    lgb_params['feature_fraction'] = space['feature_fraction']\n",
    "    lgb_params['bagging_fraction'] = space['bagging_fraction']\n",
    "    lgb_params['bagging_freq'] = int(space['bagging_freq']) if 'bagging_freq' in space else 1\n",
    "    lgb_params['nthread'] = 4\n",
    "    return lgb_params\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "obj_call_count = 0\n",
    "cur_best_score = 0 # 0 or np.inf\n",
    "log_writer = open( 'log/lgb-hyperopt-log.txt', 'w' )\n",
    "X_train = pd.read_csv('../trainx.csv')\n",
    "X_test = pd.read_csv('../testx.csv')\n",
    "Y_train = pd.read_csv('../trainy.csv', header=None)\n",
    "Y_test = pd.read_csv('../testy.csv', header=None)\n",
    "\n",
    "def objective(space):\n",
    "    global obj_call_count, cur_best_score\n",
    "\n",
    "    obj_call_count += 1\n",
    "\n",
    "    print('\\nLightGBM objective call #{} cur_best_score={:7.5f}'.format(obj_call_count,cur_best_score) )\n",
    "\n",
    "    lgb_params = get_lgb_params(space)\n",
    "\n",
    "    sorted_params = sorted(space.items(), key=lambda z: z[0])\n",
    "    params_str = str.join(' ', ['{}={}'.format(k, v) for k, v in sorted_params])\n",
    "    print('Params: {}'.format(params_str) )\n",
    "    \n",
    "    kf = KFold(n_splits=3, shuffle=True, random_state=0)\n",
    "    out_of_fold = np.zeros(len(X_train))\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X_train)):\n",
    "        D_train = lgb.Dataset(X_train.iloc[train_idx], label=Y_train.iloc[train_idx])\n",
    "        # D_train = lgb.Dataset(X_train.iloc[train_idx].values, label=Y_train.iloc[train_idx].tolist())\n",
    "        D_val = lgb.Dataset(X_train.iloc[val_idx], label=Y_train.iloc[val_idx])\n",
    "        # Train\n",
    "        num_round = 10000\n",
    "        clf = lgb.train(lgb_params,\n",
    "                           D_train,\n",
    "                           num_boost_round=num_round,\n",
    "                           # metrics='mlogloss',\n",
    "                           valid_sets=D_val,\n",
    "                           # valid_names='val',\n",
    "                           # fobj=None,\n",
    "                           # feval=None,\n",
    "                           # init_model=None,\n",
    "                           # feature_name='auto',\n",
    "                           # categorical_feature='auto',\n",
    "                           early_stopping_rounds=200,\n",
    "                           # evals_result=None,\n",
    "                           verbose_eval=False,\n",
    "                           # learning_rates=None,\n",
    "                           # keep_training_booster=False,\n",
    "                           # callbacks=None\n",
    "                           )\n",
    "        # predict\n",
    "        nb_trees = clf.best_iteration\n",
    "        print(\"nb_trees\", nb_trees)\n",
    "        val_loss = clf.best_score['valid_0']\n",
    "        print('nb_trees={} val_loss={}'.format(nb_trees, val_loss))\n",
    "        out_of_fold[val_idx] = clf.predict(X_train.iloc[val_idx], num_iteration=nb_trees)\n",
    "        score = r2_score(out_of_fold, Y_train)\n",
    "        # score = r2_score(out_of_fold, Y_train.values.reshape(-1))\n",
    "\n",
    "    print('val_r2_score={}'.format(score))\n",
    "\n",
    "    log_writer.write('score={} Params:{} nb_trees={}\\n'.format(score, params_str, nb_trees ))\n",
    "    log_writer.flush()\n",
    "\n",
    "    if score>cur_best_score:\n",
    "        cur_best_score = score\n",
    "        print(colorama.Fore.GREEN + 'NEW BEST SCORE={}'.format(cur_best_score) + colorama.Fore.RESET)\n",
    "    return {'loss': -score, 'status': STATUS_OK}\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "\n",
    "space ={\n",
    "        'num_leaves': hp.quniform ('num_leaves', 10, 100, 1),\n",
    "        'min_data_in_leaf':  hp.quniform ('min_data_in_leaf', 10, 100, 1),\n",
    "        'feature_fraction': hp.uniform('feature_fraction', 0.75, 1.0),\n",
    "        'bagging_fraction': hp.uniform('bagging_fraction', 0.75, 1.0),\n",
    "        'learning_rate': hp.uniform('learning_rate', 0, 0.01),\n",
    "#         'learning_rate': hp.loguniform('learning_rate', -5.0, -2.3),\n",
    "        'min_sum_hessian_in_leaf': hp.loguniform('min_sum_hessian_in_leaf', 0, 2.3),\n",
    "        'max_bin': hp.quniform ('max_bin', 88, 200, 1),\n",
    "        'bagging_freq': hp.quniform ('bagging_freq', 1, 15, 1),\n",
    "        'lambda_l1': hp.uniform('lambda_l1', 0, 10 ),\n",
    "        'lambda_l2': hp.uniform('lambda_l2', 0, 10 ),\n",
    "       }\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "                space=space,\n",
    "                algo=HYPEROPT_ALGO,\n",
    "                max_evals=N_HYPEROPT_PROBES,\n",
    "                trials=trials,\n",
    "                verbose=1)\n",
    "\n",
    "print('-'*50)\n",
    "print('The best params:')\n",
    "print( best )\n",
    "print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6-final"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
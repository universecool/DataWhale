{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 任务5 模型融合(3天)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 将特征放进模型中预测，并将预测结果作为新的特征加入原有特征中再经过模型预测结果（可以反复预测多次将结果加入最后的特征中）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import lightgbm as lgb\n",
    "import sklearn\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('../trainx.csv')\n",
    "X_test = pd.read_csv('../testx.csv')\n",
    "Y_train = pd.read_csv('../trainy.csv', header=None)\n",
    "Y_test = pd.read_csv('../testy.csv', header=None)\n",
    "\n",
    "feature = X_train\n",
    "label = Y_train.values.reshape(-1)\n",
    "test = X_test\n",
    "categorical_feats = list(feature.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'regression',\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"num_leaves\": 31,\n",
    "    \"max_depth\": -1,\n",
    "\n",
    "    'lambda_l1': 0.01,\n",
    "    'lambda_l2': 10,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 4, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "fold 0\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l2: 312647\tvalid_1's l2: 593375\n[1000]\ttraining's l2: 216667\tvalid_1's l2: 577079\n[1500]\ttraining's l2: 166147\tvalid_1's l2: 575640\nEarly stopping, best iteration is:\n[1314]\ttraining's l2: 181942\tvalid_1's l2: 575116\nfold 1\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l2: 324870\tvalid_1's l2: 552350\n[1000]\ttraining's l2: 222797\tvalid_1's l2: 535237\n[1500]\ttraining's l2: 171666\tvalid_1's l2: 534020\nEarly stopping, best iteration is:\n[1434]\ttraining's l2: 176831\tvalid_1's l2: 533020\nfold 2\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l2: 318611\tvalid_1's l2: 583010\n[1000]\ttraining's l2: 221888\tvalid_1's l2: 561721\n[1500]\ttraining's l2: 171151\tvalid_1's l2: 559572\nEarly stopping, best iteration is:\n[1477]\ttraining's l2: 173039\tvalid_1's l2: 559179\nr2 score0.9010301854471349\nr2:0.9023333234999357\n"
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-dea2746704c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'r2:{:}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr2_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0my_pred_final\u001b[0m\u001b[1;33m=\u001b[0m  \u001b[1;33m(\u001b[0m\u001b[0my_pre_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0my_pre_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0my_pre_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0my_pre_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0my_pre_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[0mfeature\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pre'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_feat\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pre'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_pred_final\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "    from sklearn.model_selection import KFold\n",
    "    folds = KFold(n_splits=3, shuffle=True, random_state=2333)\n",
    "   \n",
    "    \"===================================第一轮========================================================\"\n",
    "    y_pre_list = []\n",
    "    r2_list = []\n",
    "    train_feat = pd.Series()\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(feature.values, label)):\n",
    "        print(\"fold {}\".format(fold_))\n",
    "        # trn_data = lgb.Dataset(feature.iloc[trn_idx], label[trn_idx], categorical_feature=categorical_feats) # categorical_feature 参数导致内存泄露\n",
    "        # val_data = lgb.Dataset(feature.iloc[val_idx], label[val_idx], categorical_feature=categorical_feats)\n",
    "        trn_data = lgb.Dataset(feature.iloc[trn_idx], label[trn_idx], feature_name=categorical_feats)\n",
    "        val_data = lgb.Dataset(feature.iloc[val_idx], label[val_idx], feature_name=categorical_feats)\n",
    "\n",
    "        num_round = 10000\n",
    "        clf = lgb.train(params, trn_data, num_round,valid_sets=[trn_data, val_data], verbose_eval=500,\n",
    "                    early_stopping_rounds=200)\n",
    "        y_pre = clf.predict(feature.iloc[val_idx], num_iteration=clf.best_iteration)\n",
    "        r2 = r2_score(y_pre,label[val_idx])\n",
    "        r2_list.append(r2)\n",
    "        train_feat = train_feat.append(pd.Series(y_pre,index=val_idx))\n",
    "        y_pre_test = clf.predict(test,num_iteration=clf.best_iteration)\n",
    "        y_pre_list.append(y_pre_test)\n",
    "    print('r2 score{:}'.format(r2))\n",
    "    print('r2:{:}'.format(np.mean(r2_list)))\n",
    "\n",
    "    y_pred_final=  (y_pre_list[0]+y_pre_list[1]+y_pre_list[2]+y_pre_list[3]+y_pre_list[4])/5\n",
    "    feature['pre'] = train_feat\n",
    "    test['pre'] = y_pred_final\n",
    "    \"===================================第二轮========================================================\"\n",
    "    y_pre_list = []\n",
    "    r2_list = []\n",
    "    train_feat = pd.Series()\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(feature.values, label)):\n",
    "        print(\"fold {}\".format(fold_))\n",
    "        trn_data = lgb.Dataset(feature.iloc[trn_idx], label[trn_idx], feature_name=categorical_feats)\n",
    "        val_data = lgb.Dataset(feature.iloc[val_idx], label[val_idx], feature_name=categorical_feats)\n",
    "\n",
    "        num_round = 10000\n",
    "        clf = lgb.train(params, trn_data, num_round, feval=get_r2_metric,valid_sets=[trn_data, val_data], verbose_eval=500,\n",
    "                    early_stopping_rounds=200)\n",
    "        y_pre = clf.predict(feature.iloc[val_idx], num_iteration=clf.best_iteration)\n",
    "        r2 = r2_score(y_pre,label[val_idx])\n",
    "        r2_list.append(r2)\n",
    "        train_feat = train_feat.append(pd.Series(y_pre,index=val_idx))\n",
    "        y_pre_test = clf.predict(test,num_iteration=clf.best_iteration)\n",
    "        y_pre_list.append(y_pre_test)\n",
    "    print('r2 score{:}'.format(r2))\n",
    "    print('r2:{:}'.format(np.mean(r2_list)))\n",
    "    \n",
    "    y_pred_final=  (y_pre_list[0]+y_pre_list[1]+y_pre_list[2]+y_pre_list[3]+y_pre_list[4])/5\n",
    "    feature['pre_2'] = train_feat\n",
    "    test['pre_2'] = y_pred_final\n",
    "    \"=======================第三轮========================================================\"\n",
    "    y_pre_list = []\n",
    "    r2_list = []\n",
    "    train_feat = pd.Series()\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(feature.values, label)):\n",
    "        print(\"fold {}\".format(fold_))\n",
    "        trn_data = lgb.Dataset(feature.iloc[trn_idx], label[trn_idx], feature_name=categorical_feats)\n",
    "        val_data = lgb.Dataset(feature.iloc[val_idx], label[val_idx], feature_name=categorical_feats)\n",
    "\n",
    "        num_round = 10000\n",
    "        clf = lgb.train(params, trn_data, num_round, feval=get_r2_metric,valid_sets=[trn_data, val_data], verbose_eval=500,\n",
    "                    early_stopping_rounds=200)\n",
    "        y_pre = clf.predict(feature.iloc[val_idx], num_iteration=clf.best_iteration)\n",
    "        r2 = r2_score(y_pre,label[val_idx])\n",
    "        r2_list.append(r2)\n",
    "        train_feat = train_feat.append(pd.Series(y_pre,index=val_idx))\n",
    "        y_pre_test = clf.predict(test,num_iteration=clf.best_iteration)\n",
    "        y_pre_list.append(y_pre_test)\n",
    "    print('r2 score{:}'.format(r2))\n",
    "    print('r2:{:}'.format(np.mean(r2_list)))\n",
    "    \n",
    "    y_pred_final=  (y_pre_list[0]+y_pre_list[1]+y_pre_list[2]+y_pre_list[3]+y_pre_list[4])/5\n",
    "    \n",
    "    return y_pred_final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-24T12:50:18.774546Z",
     "start_time": "2019-12-24T12:50:18.769559Z"
    }
   },
   "source": [
    "# pre1-pren分别是n组模型预测出来的结果，将其进行加权融合\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = (pre1 + pre2 + pre3 +...+pren )/n\n",
    "\n",
    "pd.DataFrame(pre).to_csv(\"pre.csv\",header=None,index=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# blending\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blend(train,test,target):\n",
    "    '''5折'''\n",
    "    # n_flods = 5\n",
    "    # skf = list(StratifiedKFold(y, n_folds=n_flods))\n",
    "    '''切分训练数据集为d1,d2两部分'''\n",
    "    X_d1, X_d2, y_d1, y_d2 = train_test_split(train, target, test_size=0.5, random_state=914)\n",
    "\n",
    "    train_ = np.zeros((X_d2.shape[0],len(clfs*3)))\n",
    "    test_ = np.zeros((test.shape[0],len(clfs*3)))\n",
    "\n",
    "    for j,clf in enumerate(clfs):\n",
    "        '''依次训练各个单模型'''\n",
    "        # print(j, clf)\n",
    "        '''使用第1个部分作为预测，第2部分来训练模型，获得其预测的输出作为第2部分的新特征。'''\n",
    "        # X_train, y_train, X_test, y_test = X[train], y[train], X[test], y[test]\n",
    "        X_d1fillna=X_d1.fillna(0)\n",
    "        X_d2fillna = X_d2.fillna(0)\n",
    "\n",
    "        X_predictfillna= test.fillna(0)\n",
    "\n",
    "        clf.fit(X_d1fillna,y_d1)\n",
    "        y_submission = clf.predict(X_d2fillna)\n",
    "        y_test_submission = clf.predict(X_predictfillna)\n",
    "\n",
    "        train_[:,j*3] = y_submission*y_submission\n",
    "        '''对于测试集，直接用这k个模型的预测值作为新的特征。'''\n",
    "        test_[:, j*3] = y_test_submission*y_test_submission\n",
    "\n",
    "        train_[:, j+1] =(y_submission - y_submission.min()) /(y_submission.max() - y_submission.min())\n",
    "        '''对于测试集，直接用这k个模型的预测值作为新的特征。'''\n",
    "        y_test_submission = (y_test_submission - y_test_submission.min()) / \\\n",
    "                            (y_test_submission.max() - y_test_submission.min())\n",
    "        test_[:, j+1] = y_test_submission\n",
    "\n",
    "        train_[:, j+2] = np.log(y_submission)\n",
    "        '''对于测试集，直接用这k个模型的预测值作为新的特征。'''\n",
    "        y_test_submission =np.log(y_test_submission)\n",
    "        test_[:, j+2] = y_test_submission\n",
    "\n",
    "\n",
    "\n",
    "        # print(\"val auc Score: %f\" % r2_score(y_predict, dataset_d2[:, j]))\n",
    "        print('已完成第',j)\n",
    "\n",
    "    train_.to_csv('./input/train_blending.csv', index=False)\n",
    "    test_.to_csv('./input/test_blending.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install mlxtend\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import itertools\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from mlxtend.plotting import plot_learning_curves\n",
    "from mlxtend.plotting import plot_decision_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以python自带的鸢尾花数据集为例\n",
    "iris = datasets.load_iris()\n",
    "X, y = iris.data[:, 1:3], iris.target\n",
    "\n",
    "clf1 = KNeighborsClassifier(n_neighbors=1)\n",
    "clf2 = RandomForestClassifier(random_state=1)\n",
    "clf3 = GaussianNB()\n",
    "lr = LogisticRegression()\n",
    "sclf = StackingClassifier(classifiers=[clf1, clf2, clf3], \n",
    "                          meta_classifier=lr)\n",
    "\n",
    "label = ['KNN', 'Random Forest', 'Naive Bayes', 'Stacking Classifier']\n",
    "clf_list = [clf1, clf2, clf3, sclf]\n",
    "    \n",
    "fig = plt.figure(figsize=(10,8))\n",
    "gs = gridspec.GridSpec(2, 2)\n",
    "grid = itertools.product([0,1],repeat=2)\n",
    "\n",
    "clf_cv_mean = []\n",
    "clf_cv_std = []\n",
    "for clf, label, grd in zip(clf_list, label, grid):\n",
    "        \n",
    "    scores = cross_val_score(clf, X, y, cv=3, scoring='accuracy')\n",
    "    print(scores)\n",
    "    print(\"Accuracy: %.2f (+/- %.2f) [%s]\" %(scores.mean(), scores.std(), label))\n",
    "    clf_cv_mean.append(scores.mean())\n",
    "    clf_cv_std.append(scores.std())\n",
    "        \n",
    "    clf.fit(X, y)\n",
    "    ax = plt.subplot(gs[grd[0], grd[1]])\n",
    "    fig = plot_decision_regions(X=X, y=y, clf=clf)\n",
    "    plt.title(label)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets.load_iris(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blend(train,test,target):\n",
    "    '''5折'''\n",
    "    # n_flods = 5\n",
    "    # skf = list(StratifiedKFold(y, n_folds=n_flods))\n",
    "    '''切分训练数据集为d1,d2两部分'''\n",
    "    X_d1, X_d2, y_d1, y_d2 = train_test_split(train, target, test_size=0.5, random_state=914)\n",
    "\n",
    "    train_ = np.zeros((X_d2.shape[0],len(clfs*3)))\n",
    "    test_ = np.zeros((test.shape[0],len(clfs*3)))\n",
    "\n",
    "    for j,clf in enumerate(clfs):\n",
    "        '''依次训练各个单模型'''\n",
    "        # print(j, clf)\n",
    "        '''使用第1个部分作为预测，第2部分来训练模型，获得其预测的输出作为第2部分的新特征。'''\n",
    "        # X_train, y_train, X_test, y_test = X[train], y[train], X[test], y[test]\n",
    "        X_d1fillna=X_d1.fillna(0)\n",
    "        X_d2fillna = X_d2.fillna(0)\n",
    "\n",
    "        X_predictfillna= test.fillna(0)\n",
    "\n",
    "        clf.fit(X_d1fillna,y_d1)\n",
    "        y_submission = clf.predict(X_d2fillna)\n",
    "        y_test_submission = clf.predict(X_predictfillna)\n",
    "\n",
    "        train_[:,j*3] = y_submission*y_submission\n",
    "        '''对于测试集，直接用这k个模型的预测值作为新的特征。'''\n",
    "        test_[:, j*3] = y_test_submission*y_test_submission\n",
    "\n",
    "        train_[:, j+1] =(y_submission - y_submission.min()) /(y_submission.max() - y_submission.min())\n",
    "        '''对于测试集，直接用这k个模型的预测值作为新的特征。'''\n",
    "        y_test_submission = (y_test_submission - y_test_submission.min()) / \\\n",
    "                            (y_test_submission.max() - y_test_submission.min())\n",
    "        test_[:, j+1] = y_test_submission\n",
    "\n",
    "        train_[:, j+2] = np.log(y_submission)\n",
    "        '''对于测试集，直接用这k个模型的预测值作为新的特征。'''\n",
    "        y_test_submission =np.log(y_test_submission)\n",
    "        test_[:, j+2] = y_test_submission\n",
    "\n",
    "\n",
    "\n",
    "        # print(\"val auc Score: %f\" % r2_score(y_predict, dataset_d2[:, j]))\n",
    "        print('已完成第',j)\n",
    "\n",
    "    # train_.to_csv('./input/train_blending.csv', index=False)\n",
    "    # test_.to_csv('./input/test_blending.csv', index=False)\n",
    "    return train_, test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Random Forest\nAccuracy: 0.73 (+/- 0.01) [Random Forest]\nlr\nAccuracy: 0.76 (+/- 0.01) [lr]\nStacking Classifier\nAccuracy: 0.74 (+/- 0.01) [Stacking Classifier]\n"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression, Lasso\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from mlxtend.plotting import plot_learning_curves\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "\n",
    "\n",
    "X_train = pd.read_csv('../trainx.csv')\n",
    "X_test = pd.read_csv('../testx.csv')\n",
    "Y_train = pd.read_csv('../trainy.csv', header=None)\n",
    "Y_test = pd.read_csv('../testy.csv', header=None)\n",
    "X_train = X_train.values\n",
    "Y_train = Y_train.values.reshape(-1).astype(int)\n",
    "\n",
    "\n",
    "clf1 = KNeighborsClassifier(n_neighbors=2)\n",
    "clf2 = RandomForestClassifier(n_estimators=20, random_state=1)\n",
    "clf3 = GaussianNB()\n",
    "# lr = LogisticRegression()\n",
    "lr = Lasso()\n",
    "sclf = StackingClassifier(classifiers=[clf2, lr], \n",
    "                          meta_classifier=lr)\n",
    "\n",
    "# label = ['KNN', 'Random Forest', 'Naive Bayes', 'Stacking Classifier']\n",
    "label = ['Random Forest', 'lr', 'Stacking Classifier']\n",
    "clf_list = [clf2, lr, sclf]\n",
    "    \n",
    "fig = plt.figure(figsize=(10,8))\n",
    "gs = gridspec.GridSpec(2, 2)\n",
    "grid = itertools.product([0,1],repeat=2)\n",
    "\n",
    "clf_cv_mean = []\n",
    "clf_cv_std = []\n",
    "for clf, label, grd in zip(clf_list, label, grid):\n",
    "        \n",
    "    print(label)\n",
    "    scores = cross_val_score(clf, X_train, Y_train, cv=3, scoring='r2')\n",
    "    # print(scores)\n",
    "    print(\"Accuracy: %.2f (+/- %.2f) [%s]\" %(scores.mean(), scores.std(), label))\n",
    "    clf_cv_mean.append(scores.mean())\n",
    "    clf_cv_std.append(scores.std())\n",
    "        \n",
    "    clf.fit(X_train, Y_train)\n",
    "    ax = plt.subplot(gs[grd[0], grd[1]])\n",
    "    # fig = plot_decision_regions(X=X_train, y=Y_train, clf=clf)\n",
    "    # plt.title(label)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6-final"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}